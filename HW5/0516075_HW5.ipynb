{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for visualization of process\n",
    "from tqdm import notebook\n",
    "def tqdm(x, **kargs):\n",
    "    return notebook.tqdm(x, leave=False, **kargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset \n",
    "https://drive.google.com/drive/u/3/folders/1sHh6NvuKX6RB5OytLwf4kaqfQ9svJNDQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
    "               'dog': 5, 'frog': 6,'horse': 7,'ship': 8, 'truck': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self, datatype, transform, classes):\n",
    "        ##############################################\n",
    "        ### Initialize paths, transforms, and so on\n",
    "        ##############################################\n",
    "        self.transform = transform\n",
    "        self.images = np.load(\"./source/x_{}.npy\".format(datatype))\n",
    "        self.labels = np.load(\"./source/y_{}.npy\".format(datatype))\n",
    "        self.classes = classes\n",
    "        assert len(self.images) == len(self.labels), 'mismatched length!'\n",
    "        print(\"image shape: {}, label shape: {}\".format(self.images.shape, self.labels.shape))\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ##############################################\n",
    "        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (torchvision.Transform).\n",
    "        # 3. Return the data (e.g. image and label)\n",
    "        ##############################################\n",
    "        \n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        ##############################################\n",
    "        ### Indicate the total size of the dataset\n",
    "        ##############################################\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomRotation(5),\n",
    "        transforms.ColorJitter(brightness=0.5, contrast=0.5),\n",
    "        # transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "image shape: (50000, 32, 32, 3), label shape: (50000, 1)\n"
    }
   ],
   "source": [
    "trainset = customDataset(datatype='train',\n",
    "                         transform=data_transforms['train'],\n",
    "                         classes=class_index)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "image shape: (10000, 32, 32, 3), label shape: (10000, 1)\n"
    }
   ],
   "source": [
    "testset = customDataset(datatype='test',\n",
    "                        transform=data_transforms['test'],\n",
    "                        classes=class_index)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Size of image: torch.Size([100, 3, 32, 32])\nType of image: torch.float32\nSize of label: torch.Size([100, 1])\nType of label: torch.int64\n"
    }
   ],
   "source": [
    "for imgs, lbls in trainloader:\n",
    "    print('Size of image:', imgs.size())  \n",
    "    print('Type of image:', imgs.dtype)   \n",
    "    print('Size of label:', lbls.size())  \n",
    "    print('Type of label:', lbls.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model & training (Pytorch)\n",
    "> https://juejin.im/entry/5bf51d35e51d454049668d57  \n",
    "> https://github.com/Aleadinglight/Pytorch-VGG-19/blob/master/VGG_19.ipynb?fbclid=IwAR15GpLCFuTC2xxz3VXb5KJd4wjpyCxEkT4KJ1MDkOlv73DwZSc7vBC7KRo  \n",
    "> https://zhpmatrix.github.io/2019/03/11/conv-highlights-in-pytorch/  \n",
    "> https://paperswithcode.com/sota/image-classification-on-cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Net(\n  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu1): ReLU(inplace=True)\n  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu2): ReLU(inplace=True)\n  (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv7): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu3): ReLU(inplace=True)\n  (conv8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv10): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu4): ReLU(inplace=True)\n  (conv11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (conv13): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n  (pool5): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu5): ReLU(inplace=True)\n  (fc14): Linear(in_features=8192, out_features=1024, bias=True)\n  (drop1): Dropout(p=0.5, inplace=False)\n  (fc15): Linear(in_features=1024, out_features=1024, bias=True)\n  (drop2): Dropout(p=0.5, inplace=False)\n  (fc16): Linear(in_features=1024, out_features=10, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 128, 1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv8 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(256, 256, 1, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv11 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(512, 512, 1, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.fc14 = nn.Linear(512 * 4 * 4, 1024)\n",
    "        self.drop1 = nn.Dropout(p=0.5)\n",
    "        self.fc15 = nn.Linear(1024, 1024)\n",
    "        self.drop2 = nn.Dropout(p=0.5)\n",
    "        self.fc16 = nn.Linear(1024, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "\n",
    "        x = self.conv8(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "\n",
    "        x = self.conv11(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.conv13(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.pool5(x)\n",
    "        \n",
    "\n",
    "        x = x.view(-1, 512 * 4 * 4)\n",
    "        x = F.relu(self.fc14(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.fc15(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc16(x)\n",
    "\n",
    "        return x\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epochs: ', style=ProgressStyle(description_width='initial…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c5e6e5f77634f5abf598411b41d68ff"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1,   500] loss: 1.973\nAccuracy of my model on test set:  0.3351\n[2,   500] loss: 1.529\nAccuracy of my model on test set:  0.5455\n[3,   500] loss: 1.218\nAccuracy of my model on test set:  0.6221\n[4,   500] loss: 1.020\nAccuracy of my model on test set:  0.6872\n[5,   500] loss: 0.898\nAccuracy of my model on test set:  0.7371\n[6,   500] loss: 0.804\nAccuracy of my model on test set:  0.7568\n[7,   500] loss: 0.733\nAccuracy of my model on test set:  0.7802\n[8,   500] loss: 0.672\nAccuracy of my model on test set:  0.7934\n[9,   500] loss: 0.622\nAccuracy of my model on test set:  0.8061\n[10,   500] loss: 0.580\nAccuracy of my model on test set:  0.8136\n[11,   500] loss: 0.549\nAccuracy of my model on test set:  0.83\n[12,   500] loss: 0.512\nAccuracy of my model on test set:  0.8304\n[13,   500] loss: 0.492\nAccuracy of my model on test set:  0.8317\n[14,   500] loss: 0.462\nAccuracy of my model on test set:  0.846\n[15,   500] loss: 0.443\nAccuracy of my model on test set:  0.8465\n[16,   500] loss: 0.425\nAccuracy of my model on test set:  0.8476\n[17,   500] loss: 0.397\nAccuracy of my model on test set:  0.854\n[18,   500] loss: 0.386\nAccuracy of my model on test set:  0.852\n[19,   500] loss: 0.359\nAccuracy of my model on test set:  0.851\n[20,   500] loss: 0.350\nAccuracy of my model on test set:  0.8636\n[21,   500] loss: 0.334\nAccuracy of my model on test set:  0.8622\n[22,   500] loss: 0.324\nAccuracy of my model on test set:  0.8539\n[23,   500] loss: 0.307\nAccuracy of my model on test set:  0.8652\n[24,   500] loss: 0.300\nAccuracy of my model on test set:  0.8534\n[25,   500] loss: 0.286\nAccuracy of my model on test set:  0.8661\n[26,   500] loss: 0.270\nAccuracy of my model on test set:  0.8711\n[27,   500] loss: 0.266\nAccuracy of my model on test set:  0.8736\n[28,   500] loss: 0.254\nAccuracy of my model on test set:  0.8697\n[29,   500] loss: 0.243\nAccuracy of my model on test set:  0.8685\n[30,   500] loss: 0.239\nAccuracy of my model on test set:  0.8658\n[31,   500] loss: 0.225\nAccuracy of my model on test set:  0.8727\n[32,   500] loss: 0.219\nAccuracy of my model on test set:  0.8688\n[33,   500] loss: 0.213\nAccuracy of my model on test set:  0.8743\n[34,   500] loss: 0.205\nAccuracy of my model on test set:  0.8776\n[35,   500] loss: 0.198\nAccuracy of my model on test set:  0.8747\n[36,   500] loss: 0.185\nAccuracy of my model on test set:  0.87\n[37,   500] loss: 0.186\nAccuracy of my model on test set:  0.8779\n[38,   500] loss: 0.176\nAccuracy of my model on test set:  0.8735\n[39,   500] loss: 0.172\nAccuracy of my model on test set:  0.8788\n[40,   500] loss: 0.172\nAccuracy of my model on test set:  0.8807\n[41,   500] loss: 0.161\nAccuracy of my model on test set:  0.876\n[42,   500] loss: 0.158\nAccuracy of my model on test set:  0.8775\n[43,   500] loss: 0.150\nAccuracy of my model on test set:  0.8831\n[44,   500] loss: 0.148\nAccuracy of my model on test set:  0.8828\n[45,   500] loss: 0.140\nAccuracy of my model on test set:  0.885\n[46,   500] loss: 0.137\nAccuracy of my model on test set:  0.8774\n[47,   500] loss: 0.138\nAccuracy of my model on test set:  0.8815\n[48,   500] loss: 0.133\nAccuracy of my model on test set:  0.878\n[49,   500] loss: 0.132\nAccuracy of my model on test set:  0.8859\n[50,   500] loss: 0.120\nAccuracy of my model on test set:  0.8784\n[51,   500] loss: 0.124\nAccuracy of my model on test set:  0.875\n[52,   500] loss: 0.122\nAccuracy of my model on test set:  0.8804\n[53,   500] loss: 0.115\nAccuracy of my model on test set:  0.8867\n[54,   500] loss: 0.115\nAccuracy of my model on test set:  0.8749\n[55,   500] loss: 0.110\nAccuracy of my model on test set:  0.8838\n[56,   500] loss: 0.105\nAccuracy of my model on test set:  0.8854\n[57,   500] loss: 0.109\nAccuracy of my model on test set:  0.8775\n[58,   500] loss: 0.101\nAccuracy of my model on test set:  0.8801\n[59,   500] loss: 0.096\nAccuracy of my model on test set:  0.8818\n[60,   500] loss: 0.098\nAccuracy of my model on test set:  0.8829\n[61,   500] loss: 0.097\nAccuracy of my model on test set:  0.8808\n[62,   500] loss: 0.090\nAccuracy of my model on test set:  0.8844\n[63,   500] loss: 0.096\nAccuracy of my model on test set:  0.8915\n[64,   500] loss: 0.090\nAccuracy of my model on test set:  0.88\n[65,   500] loss: 0.092\nAccuracy of my model on test set:  0.8868\n[66,   500] loss: 0.085\nAccuracy of my model on test set:  0.8827\n[67,   500] loss: 0.088\nAccuracy of my model on test set:  0.8901\n[68,   500] loss: 0.085\nAccuracy of my model on test set:  0.8849\n[69,   500] loss: 0.081\nAccuracy of my model on test set:  0.8903\n[70,   500] loss: 0.080\nAccuracy of my model on test set:  0.8836\n[71,   500] loss: 0.079\nAccuracy of my model on test set:  0.8816\n[72,   500] loss: 0.078\nAccuracy of my model on test set:  0.8851\n[73,   500] loss: 0.075\nAccuracy of my model on test set:  0.8782\n[74,   500] loss: 0.076\nAccuracy of my model on test set:  0.8865\n[75,   500] loss: 0.073\nAccuracy of my model on test set:  0.8801\n[76,   500] loss: 0.073\nAccuracy of my model on test set:  0.8809\n[77,   500] loss: 0.074\nAccuracy of my model on test set:  0.8875\n[78,   500] loss: 0.073\nAccuracy of my model on test set:  0.8854\n[79,   500] loss: 0.070\nAccuracy of my model on test set:  0.8791\n[80,   500] loss: 0.068\nAccuracy of my model on test set:  0.8807\n[81,   500] loss: 0.068\nAccuracy of my model on test set:  0.8892\n[82,   500] loss: 0.063\nAccuracy of my model on test set:  0.8826\n[83,   500] loss: 0.068\nAccuracy of my model on test set:  0.8874\n[84,   500] loss: 0.065\nAccuracy of my model on test set:  0.8905\n[85,   500] loss: 0.061\nAccuracy of my model on test set:  0.891\n[86,   500] loss: 0.061\nAccuracy of my model on test set:  0.8836\n[87,   500] loss: 0.064\nAccuracy of my model on test set:  0.8853\n[88,   500] loss: 0.064\nAccuracy of my model on test set:  0.8855\n[89,   500] loss: 0.064\nAccuracy of my model on test set:  0.8901\n[90,   500] loss: 0.057\nAccuracy of my model on test set:  0.8886\n[91,   500] loss: 0.060\nAccuracy of my model on test set:  0.8878\n[92,   500] loss: 0.058\nAccuracy of my model on test set:  0.888\n[93,   500] loss: 0.059\nAccuracy of my model on test set:  0.8853\n[94,   500] loss: 0.060\nAccuracy of my model on test set:  0.8848\n[95,   500] loss: 0.057\nAccuracy of my model on test set:  0.8816\n[96,   500] loss: 0.056\nAccuracy of my model on test set:  0.8901\n[97,   500] loss: 0.059\nAccuracy of my model on test set:  0.8883\n[98,   500] loss: 0.055\nAccuracy of my model on test set:  0.8837\n[99,   500] loss: 0.056\nAccuracy of my model on test set:  0.8846\n[100,   500] loss: 0.059\nAccuracy of my model on test set:  0.8891\n"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(net.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay=1e-4)\n",
    "epochs = 100\n",
    "size = 50000 // batch_size\n",
    "for epoch in tqdm(range(epochs), desc='Epochs: '):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % size == (size - 1):    # print every size mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / size))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Predict results\n",
    "    y_pred_torch = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for data_test in testloader:\n",
    "            images, labels = data_test[0].to(device), data_test[1].to(device)\n",
    "            labels = labels.view(-1)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_pred_torch = np.hstack([y_pred_torch, predicted.cpu().detach().numpy()])\n",
    "    y_test = np.load(\"./source/y_test.npy\")\n",
    "    print(\"Accuracy of my model on test set: \", accuracy_score(y_test, y_pred_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Epochs: ', style=ProgressStyle(description_width='initial…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "480b121b78a54b15942cc87e145b250b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1,   500] loss: 0.029\nAccuracy of my model on test set:  0.8991\n[2,   500] loss: 0.019\nAccuracy of my model on test set:  0.9001\n[3,   500] loss: 0.015\nAccuracy of my model on test set:  0.9015\n[4,   500] loss: 0.014\nAccuracy of my model on test set:  0.9019\n[5,   500] loss: 0.012\nAccuracy of my model on test set:  0.9022\n[6,   500] loss: 0.011\nAccuracy of my model on test set:  0.9022\n[7,   500] loss: 0.011\nAccuracy of my model on test set:  0.9021\n[8,   500] loss: 0.010\nAccuracy of my model on test set:  0.9033\n[9,   500] loss: 0.009\nAccuracy of my model on test set:  0.9028\n[10,   500] loss: 0.008\nAccuracy of my model on test set:  0.9015\n[11,   500] loss: 0.009\nAccuracy of my model on test set:  0.9012\n[12,   500] loss: 0.008\nAccuracy of my model on test set:  0.9035\n[13,   500] loss: 0.008\nAccuracy of my model on test set:  0.9017\n[14,   500] loss: 0.007\nAccuracy of my model on test set:  0.9027\n[15,   500] loss: 0.007\nAccuracy of my model on test set:  0.9026\n[16,   500] loss: 0.007\nAccuracy of my model on test set:  0.9016\n[17,   500] loss: 0.007\nAccuracy of my model on test set:  0.9033\n[18,   500] loss: 0.007\nAccuracy of my model on test set:  0.9028\n[19,   500] loss: 0.007\nAccuracy of my model on test set:  0.9006\n[20,   500] loss: 0.007\nAccuracy of my model on test set:  0.9016\n[21,   500] loss: 0.006\nAccuracy of my model on test set:  0.9015\n[22,   500] loss: 0.006\nAccuracy of my model on test set:  0.9036\n[23,   500] loss: 0.005\nAccuracy of my model on test set:  0.9016\n[24,   500] loss: 0.006\nAccuracy of my model on test set:  0.9025\n[25,   500] loss: 0.006\nAccuracy of my model on test set:  0.9025\n[26,   500] loss: 0.006\nAccuracy of my model on test set:  0.9029\n[27,   500] loss: 0.005\nAccuracy of my model on test set:  0.9038\n[28,   500] loss: 0.005\nAccuracy of my model on test set:  0.9022\n[29,   500] loss: 0.006\nAccuracy of my model on test set:  0.9036\n[30,   500] loss: 0.005\nAccuracy of my model on test set:  0.9021\n[31,   500] loss: 0.005\nAccuracy of my model on test set:  0.9022\n[32,   500] loss: 0.005\nAccuracy of my model on test set:  0.9035\n[33,   500] loss: 0.005\nAccuracy of my model on test set:  0.9028\n[34,   500] loss: 0.004\nAccuracy of my model on test set:  0.9029\n[35,   500] loss: 0.005\nAccuracy of my model on test set:  0.9046\n[36,   500] loss: 0.005\nAccuracy of my model on test set:  0.9025\n[37,   500] loss: 0.004\nAccuracy of my model on test set:  0.9024\n[38,   500] loss: 0.004\nAccuracy of my model on test set:  0.9021\n[39,   500] loss: 0.005\nAccuracy of my model on test set:  0.9026\n[40,   500] loss: 0.005\nAccuracy of my model on test set:  0.9027\n[41,   500] loss: 0.005\nAccuracy of my model on test set:  0.904\n[42,   500] loss: 0.004\nAccuracy of my model on test set:  0.9036\n[43,   500] loss: 0.005\nAccuracy of my model on test set:  0.9016\n[44,   500] loss: 0.004\nAccuracy of my model on test set:  0.9038\n[45,   500] loss: 0.004\nAccuracy of my model on test set:  0.9031\n[46,   500] loss: 0.004\nAccuracy of my model on test set:  0.9032\n[47,   500] loss: 0.005\nAccuracy of my model on test set:  0.9029\n[48,   500] loss: 0.004\nAccuracy of my model on test set:  0.9034\n[49,   500] loss: 0.004\nAccuracy of my model on test set:  0.9035\n[50,   500] loss: 0.004\nAccuracy of my model on test set:  0.9024\n[51,   500] loss: 0.003\nAccuracy of my model on test set:  0.9017\n[52,   500] loss: 0.004\nAccuracy of my model on test set:  0.9031\n[53,   500] loss: 0.005\nAccuracy of my model on test set:  0.9017\n[54,   500] loss: 0.004\nAccuracy of my model on test set:  0.9022\n[55,   500] loss: 0.003\nAccuracy of my model on test set:  0.9017\n[56,   500] loss: 0.003\nAccuracy of my model on test set:  0.9035\n[57,   500] loss: 0.004\nAccuracy of my model on test set:  0.9029\n[58,   500] loss: 0.004\nAccuracy of my model on test set:  0.9027\n[59,   500] loss: 0.003\nAccuracy of my model on test set:  0.9046\n[60,   500] loss: 0.004\nAccuracy of my model on test set:  0.9045\n[61,   500] loss: 0.003\nAccuracy of my model on test set:  0.9038\n[62,   500] loss: 0.004\nAccuracy of my model on test set:  0.9019\n[63,   500] loss: 0.003\nAccuracy of my model on test set:  0.9032\n[64,   500] loss: 0.003\nAccuracy of my model on test set:  0.9012\n[65,   500] loss: 0.003\nAccuracy of my model on test set:  0.9034\n[66,   500] loss: 0.003\nAccuracy of my model on test set:  0.9012\n[67,   500] loss: 0.003\nAccuracy of my model on test set:  0.9016\n[68,   500] loss: 0.003\nAccuracy of my model on test set:  0.9021\n[69,   500] loss: 0.003\nAccuracy of my model on test set:  0.9014\n[70,   500] loss: 0.003\nAccuracy of my model on test set:  0.9026\n[71,   500] loss: 0.003\nAccuracy of my model on test set:  0.9047\n[72,   500] loss: 0.003\nAccuracy of my model on test set:  0.9031\n[73,   500] loss: 0.003\nAccuracy of my model on test set:  0.905\n[74,   500] loss: 0.002\nAccuracy of my model on test set:  0.9044\n[75,   500] loss: 0.002\nAccuracy of my model on test set:  0.9048\n[76,   500] loss: 0.004\nAccuracy of my model on test set:  0.9031\n[77,   500] loss: 0.003\nAccuracy of my model on test set:  0.9041\n[78,   500] loss: 0.003\nAccuracy of my model on test set:  0.903\n[79,   500] loss: 0.003\nAccuracy of my model on test set:  0.9016\n[80,   500] loss: 0.003\nAccuracy of my model on test set:  0.9022\n[81,   500] loss: 0.003\nAccuracy of my model on test set:  0.9042\n[82,   500] loss: 0.003\nAccuracy of my model on test set:  0.9039\n[83,   500] loss: 0.003\nAccuracy of my model on test set:  0.9019\n[84,   500] loss: 0.003\nAccuracy of my model on test set:  0.9031\n[85,   500] loss: 0.003\nAccuracy of my model on test set:  0.9029\n[86,   500] loss: 0.003\nAccuracy of my model on test set:  0.9031\n[87,   500] loss: 0.003\nAccuracy of my model on test set:  0.9021\n[88,   500] loss: 0.003\nAccuracy of my model on test set:  0.9041\n[89,   500] loss: 0.003\nAccuracy of my model on test set:  0.9028\n[90,   500] loss: 0.002\nAccuracy of my model on test set:  0.9035\n[91,   500] loss: 0.003\nAccuracy of my model on test set:  0.9037\n[92,   500] loss: 0.002\nAccuracy of my model on test set:  0.9012\n[93,   500] loss: 0.002\nAccuracy of my model on test set:  0.9019\n[94,   500] loss: 0.003\nAccuracy of my model on test set:  0.9034\n[95,   500] loss: 0.003\nAccuracy of my model on test set:  0.9033\n[96,   500] loss: 0.002\nAccuracy of my model on test set:  0.9021\n[97,   500] loss: 0.002\nAccuracy of my model on test set:  0.9026\n[98,   500] loss: 0.002\nAccuracy of my model on test set:  0.903\n[99,   500] loss: 0.002\nAccuracy of my model on test set:  0.9035\n[100,   500] loss: 0.002\nAccuracy of my model on test set:  0.9028\n"
    }
   ],
   "source": [
    "# 30~40 use 1e-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(net.parameters(), lr=1e-5, weight_decay=1e-5)\n",
    "optimizer = optim.SGD(net.parameters(), lr=1e-2, weight_decay=1e-4)\n",
    "epochs = 100\n",
    "size = 50000 // batch_size\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc='Epochs: '):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % size == (size - 1):    # print every size mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / size))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Predict results\n",
    "    y_pred_torch = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for data_test in testloader:\n",
    "            images, labels = data_test[0].to(device), data_test[1].to(device)\n",
    "            labels = labels.view(-1)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_pred_torch = np.hstack([y_pred_torch, predicted.cpu().detach().numpy()])\n",
    "    y_test = np.load(\"./source/y_test.npy\")\n",
    "    print(\"Accuracy of my model on test set: \", accuracy_score(y_test, y_pred_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = np.array([])\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        labels = labels.view(-1)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred = np.hstack([y_pred, predicted.cpu().detach().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(10000,)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT MODIFY CODE BELOW!\n",
    "**Please screen shot your results and post it on your report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy of my model on test set:  0.9024\n"
    }
   ],
   "source": [
    "y_test = np.load(\"./source/y_test.npy\")\n",
    "print(\"Accuracy of my model on test set: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}