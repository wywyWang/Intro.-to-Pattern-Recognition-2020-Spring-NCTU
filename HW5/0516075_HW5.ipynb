{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for visualization of process\n",
    "from tqdm import notebook\n",
    "def tqdm(x, **kargs):\n",
    "    return notebook.tqdm(x, leave=False, **kargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset \n",
    "https://drive.google.com/drive/u/3/folders/1sHh6NvuKX6RB5OytLwf4kaqfQ9svJNDQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
    "               'dog': 5, 'frog': 6,'horse': 7,'ship': 8, 'truck': 9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self, datatype, transform, classes):\n",
    "        ##############################################\n",
    "        ### Initialize paths, transforms, and so on\n",
    "        ##############################################\n",
    "        self.transform = transform\n",
    "        self.images = np.load(\"./source/x_{}.npy\".format(datatype))\n",
    "        self.labels = np.load(\"./source/y_{}.npy\".format(datatype))\n",
    "        self.classes = classes\n",
    "        assert len(self.images) == len(self.labels), 'mismatched length!'\n",
    "        print(\"image shape: {}, label shape: {}\".format(self.images.shape, self.labels.shape))\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ##############################################\n",
    "        # 1. Read from file (using numpy.fromfile, PIL.Image.open)\n",
    "        # 2. Preprocess the data (torchvision.Transform).\n",
    "        # 3. Return the data (e.g. image and label)\n",
    "        ##############################################\n",
    "        \n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        ##############################################\n",
    "        ### Indicate the total size of the dataset\n",
    "        ##############################################\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (50000, 32, 32, 3), label shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "trainset = customDataset(datatype='train',\n",
    "                         transform=data_transforms['train'],\n",
    "                         classes=class_index)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (10000, 32, 32, 3), label shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "testset = customDataset(datatype='test',\n",
    "                        transform=data_transforms['test'],\n",
    "                        classes=class_index)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of image: torch.Size([8, 3, 32, 32])\n",
      "Type of image: torch.float32\n",
      "Size of label: torch.Size([8, 1])\n",
      "Type of label: torch.int64\n",
      "tensor([[[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          ...,\n",
      "          [-1.1884,  0.1297,  1.3704,  ..., -1.1690, -1.4211, -1.5374],\n",
      "          [-1.0527, -0.6650,  0.0328,  ..., -1.4211, -1.4598, -1.5180],\n",
      "          [-1.2660, -1.0140, -0.9558,  ..., -1.6343, -1.4792, -1.3629]],\n",
      "\n",
      "         [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          ...,\n",
      "          [-0.9236,  0.1974,  1.2594,  ..., -1.0022, -1.1596, -1.3169],\n",
      "          [-0.5892, -0.3336,  0.2171,  ..., -1.1989, -1.1596, -1.2579],\n",
      "          [-0.7072, -0.5499, -0.5499,  ..., -1.3759, -1.1202, -1.0809]],\n",
      "\n",
      "         [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          ...,\n",
      "          [-1.5971, -0.1728,  1.1344,  ..., -1.5971, -1.7336, -1.8507],\n",
      "          [-1.3629, -0.8947, -0.1338,  ..., -1.8117, -1.7727, -1.8117],\n",
      "          [-1.5580, -1.2459, -1.1483,  ..., -1.9678, -1.7336, -1.6556]]],\n",
      "\n",
      "\n",
      "        [[[-2.1964, -2.1964, -2.1964,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.1964, -2.1964, -2.1964,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.1964, -2.1964, -2.1964,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          ...,\n",
      "          [-1.0721, -0.5293, -0.5293,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-0.8589, -0.4906, -0.4712,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-0.6263, -0.3161, -0.3549,  ..., -2.4291, -2.4291, -2.4291]],\n",
      "\n",
      "         [[-2.2019, -2.2019, -2.2019,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.2019, -2.2019, -2.2019,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.2019, -2.2019, -2.2019,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          ...,\n",
      "          [-1.3759, -1.0416, -1.1989,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-1.2382, -1.0219, -1.1006,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-1.1399, -0.9236, -1.0022,  ..., -2.4183, -2.4183, -2.4183]],\n",
      "\n",
      "         [[-2.0458, -2.0458, -2.0458,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.0458, -2.0458, -2.0458,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.0458, -2.0458, -2.0458,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          ...,\n",
      "          [-1.2459, -0.9922, -1.1873,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-1.1288, -1.0313, -1.1483,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-1.0118, -0.8947, -1.0118,  ..., -2.2214, -2.2214, -2.2214]]],\n",
      "\n",
      "\n",
      "        [[[-2.4291, -2.4291, -2.4291,  ...,  2.4753,  2.4753,  2.4753],\n",
      "          [-2.4291, -2.4291, -2.4291,  ...,  2.5141,  2.5141,  2.5141],\n",
      "          [-2.4291, -2.4291, -2.4291,  ...,  2.5141,  2.5141,  2.5141],\n",
      "          ...,\n",
      "          [-2.4291, -2.4291, -2.4291,  ...,  0.7307,  2.2815,  2.5141],\n",
      "          [-2.4291, -2.4291, -2.4291,  ...,  2.2233,  2.4753,  2.4559],\n",
      "          [-2.4291, -2.4291, -2.4291,  ...,  2.4947,  2.4172,  2.4559]],\n",
      "\n",
      "         [[-2.4183, -2.4183, -2.4183,  ...,  2.5575,  2.5575,  2.5575],\n",
      "          [-2.4183, -2.4183, -2.4183,  ...,  2.5968,  2.5968,  2.5968],\n",
      "          [-2.4183, -2.4183, -2.4183,  ...,  2.5968,  2.5968,  2.5968],\n",
      "          ...,\n",
      "          [-2.4183, -2.4183, -2.4183,  ...,  0.6104,  2.2821,  2.5968],\n",
      "          [-2.4183, -2.4183, -2.4183,  ...,  2.2231,  2.5378,  2.5771],\n",
      "          [-2.4183, -2.4183, -2.4183,  ...,  2.5575,  2.5181,  2.5575]],\n",
      "\n",
      "         [[-2.2214, -2.2214, -2.2214,  ...,  2.7147,  2.7147,  2.7147],\n",
      "          [-2.2214, -2.2214, -2.2214,  ...,  2.7537,  2.7537,  2.7537],\n",
      "          [-2.2214, -2.2214, -2.2214,  ...,  2.7537,  2.7537,  2.7537],\n",
      "          ...,\n",
      "          [-2.2214, -2.2214, -2.2214,  ...,  0.1784,  2.4025,  2.7147],\n",
      "          [-2.2214, -2.2214, -2.2214,  ...,  2.1294,  2.7147,  2.6562],\n",
      "          [-2.2214, -2.2214, -2.2214,  ...,  2.6952,  2.6757,  2.6952]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.4291,  1.5061,  1.6224,  ...,  1.9519,  1.8938,  1.8550],\n",
      "          [-2.4291,  1.4673,  1.5642,  ...,  1.9519,  1.9325,  1.8938],\n",
      "          [-2.4291,  1.4285,  1.4479,  ...,  1.8744,  1.8550,  1.8356],\n",
      "          ...,\n",
      "          [-2.4291,  1.8162,  1.9713,  ...,  1.4285,  0.7694,  0.6338],\n",
      "          [-2.4291,  1.7968,  1.4673,  ...,  1.4091,  0.7888,  0.6338],\n",
      "          [-2.4291,  2.0489,  1.5255,  ...,  1.3704,  0.8082,  0.6919]],\n",
      "\n",
      "         [[-2.4183,  1.7904,  1.8495,  ...,  2.1248,  2.0658,  2.0265],\n",
      "          [-2.4183,  1.8101,  1.8298,  ...,  2.1248,  2.1051,  2.0658],\n",
      "          [-2.4183,  1.8101,  1.7708,  ...,  2.0461,  2.0265,  2.0068],\n",
      "          ...,\n",
      "          [-2.4183,  2.0658,  2.2625,  ...,  1.1414,  0.3941,  0.2564],\n",
      "          [-2.4183,  2.0265,  1.7511,  ...,  1.0431,  0.3941,  0.3154],\n",
      "          [-2.4183,  2.2231,  1.7904,  ...,  0.9448,  0.4138,  0.3941]],\n",
      "\n",
      "         [[-2.2214,  0.8807,  0.8807,  ...,  1.2319,  1.1734,  1.1344],\n",
      "          [-2.2214,  0.9393,  0.9393,  ...,  1.2319,  1.2124,  1.1734],\n",
      "          [-2.2214,  1.0758,  0.9783,  ...,  1.1539,  1.1539,  1.1149],\n",
      "          ...,\n",
      "          [-2.2214,  1.8953,  2.0123,  ..., -0.6606, -1.3239, -1.1093],\n",
      "          [-2.2214,  1.8563,  1.5051,  ..., -0.8167, -1.1678, -0.9532],\n",
      "          [-2.2214,  2.0709,  1.5441,  ..., -0.8557, -0.9532, -0.7581]]],\n",
      "\n",
      "\n",
      "        [[[-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-1.7700, -1.6924, -1.4404,  ..., -2.0414, -2.4291, -2.4291],\n",
      "          [-1.8281, -1.7700, -1.4986,  ..., -2.0995, -2.4291, -2.4291],\n",
      "          ...,\n",
      "          [ 1.1378,  1.1378,  1.1571,  ...,  1.1571, -2.4291, -2.4291],\n",
      "          [ 1.0214,  1.0214,  1.0214,  ...,  1.0214, -2.4291, -2.4291],\n",
      "          [ 1.0214,  1.0021,  1.0021,  ...,  1.0408, -2.4291, -2.4291]],\n",
      "\n",
      "         [[-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-1.6119, -1.7299, -1.6709,  ..., -1.9463, -2.4183, -2.4183],\n",
      "          [-1.6906, -1.7692, -1.6512,  ..., -2.0053, -2.4183, -2.4183],\n",
      "          ...,\n",
      "          [ 1.2791,  1.2791,  1.2988,  ...,  1.2988, -2.4183, -2.4183],\n",
      "          [ 1.1611,  1.1611,  1.1611,  ...,  1.1611, -2.4183, -2.4183],\n",
      "          [ 1.1611,  1.1414,  1.1414,  ...,  1.1808, -2.4183, -2.4183]],\n",
      "\n",
      "         [[-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-1.2264, -1.4410, -1.4800,  ..., -1.7727, -2.2214, -2.2214],\n",
      "          [-1.2849, -1.4800, -1.4800,  ..., -1.8312, -2.2214, -2.2214],\n",
      "          ...,\n",
      "          [ 1.5051,  1.5051,  1.5246,  ...,  1.5246, -2.2214, -2.2214],\n",
      "          [ 1.4075,  1.3880,  1.3880,  ...,  1.3880, -2.2214, -2.2214],\n",
      "          [ 1.3880,  1.3685,  1.3685,  ...,  1.4075, -2.2214, -2.2214]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7193,  1.7193,  1.7193,  ...,  1.7387, -2.4291, -2.4291],\n",
      "          [ 1.6999,  1.6805,  1.7193,  ...,  1.5061, -2.4291, -2.4291],\n",
      "          [ 1.6224,  1.6224,  1.6418,  ...,  1.2347, -2.4291, -2.4291],\n",
      "          ...,\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291],\n",
      "          [-2.4291, -2.4291, -2.4291,  ..., -2.4291, -2.4291, -2.4291]],\n",
      "\n",
      "         [[ 1.7708,  1.7708,  1.7708,  ...,  1.8101, -2.4183, -2.4183],\n",
      "          [ 1.7708,  1.7511,  1.7708,  ...,  1.5741, -2.4183, -2.4183],\n",
      "          [ 1.6921,  1.6921,  1.7118,  ...,  1.3184, -2.4183, -2.4183],\n",
      "          ...,\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183],\n",
      "          [-2.4183, -2.4183, -2.4183,  ..., -2.4183, -2.4183, -2.4183]],\n",
      "\n",
      "         [[ 2.0904,  2.0904,  2.0904,  ...,  2.1294, -2.2214, -2.2214],\n",
      "          [ 2.0904,  2.0709,  2.0904,  ...,  1.9343, -2.2214, -2.2214],\n",
      "          [ 2.0123,  2.0123,  2.0319,  ...,  1.7002, -2.2214, -2.2214],\n",
      "          ...,\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214],\n",
      "          [-2.2214, -2.2214, -2.2214,  ..., -2.2214, -2.2214, -2.2214]]]])\n",
      "tensor([[5],\n",
      "        [6],\n",
      "        [6],\n",
      "        [3],\n",
      "        [7],\n",
      "        [3],\n",
      "        [5],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "for imgs, lbls in trainloader:\n",
    "    print('Size of image:', imgs.size())  \n",
    "    print('Type of image:', imgs.dtype)   \n",
    "    print('Size of label:', lbls.size())  \n",
    "    print('Type of label:', lbls.dtype)\n",
    "    \n",
    "    print(imgs)\n",
    "    print(lbls)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model & training (Pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epochs: ', max=2.0, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epochs: ', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Epochs: ', max=1.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epochs), desc='Epochs: '):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm(enumerate(trainloader, 0), desc='Epochs: '):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "#         if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "#             print('[%d, %5d] loss: %.3f' %\n",
    "#                   (epoch + 1, i + 1, running_loss / 2000))\n",
    "#             running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0 : 47.895791583166336%\n",
      "Accuracy of 1 : 70.16460905349794%\n",
      "Accuracy of 2 : 35.2%\n",
      "Accuracy of 3 : 38.113207547169814%\n",
      "Accuracy of 4 : 38.10444874274661%\n",
      "Accuracy of 5 : 32.10633946830266%\n",
      "Accuracy of 6 : 68.7007874015748%\n",
      "Accuracy of 7 : 64.04255319148936%\n",
      "Accuracy of 8 : 71.83673469387755%\n",
      "Accuracy of 9 : 59.29549902152642%\n"
     ]
    }
   ],
   "source": [
    "class_correct = [0 for _ in range(len(class_index))]\n",
    "class_total = [0 for _ in range(len(class_index))]\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        labels = labels.view(-1)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_pred.append(predicted.cpu().detach().numpy())\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of {} : {}%'.format(i, 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(len(y_pred)):\n",
    "    for j in range(8):\n",
    "        test.append(y_pred[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = test.copy()\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 6, 5, ..., 9, 8, 9])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model & training (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 24s 478us/step - loss: 1.8933 - acc: 0.3203 - val_loss: 1.5972 - val_acc: 0.4367\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 43s 867us/step - loss: 1.4593 - acc: 0.4818 - val_loss: 1.3575 - val_acc: 0.5240\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 34s 686us/step - loss: 1.2797 - acc: 0.5500 - val_loss: 1.2541 - val_acc: 0.5644\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 36s 720us/step - loss: 1.1661 - acc: 0.5923 - val_loss: 1.2103 - val_acc: 0.5730\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 37s 744us/step - loss: 1.0775 - acc: 0.6257 - val_loss: 1.0946 - val_acc: 0.6187\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 45s 908us/step - loss: 1.0061 - acc: 0.6518 - val_loss: 1.0458 - val_acc: 0.6334\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 29s 589us/step - loss: 0.9396 - acc: 0.6733 - val_loss: 0.9805 - val_acc: 0.6602\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 0.8805 - acc: 0.6962 - val_loss: 1.0253 - val_acc: 0.6436\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 37s 730us/step - loss: 0.8243 - acc: 0.7157 - val_loss: 1.0043 - val_acc: 0.6524\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 32s 639us/step - loss: 0.7681 - acc: 0.7347 - val_loss: 0.9311 - val_acc: 0.6769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f25a747dcf8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Builde model\n",
    "model = Sequential() # Sequential groups a linear stack of layers \n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=x_train.shape[1:])) # Add Convolution layers\n",
    "model.add(Activation('relu')) # Add Relu activation for non-linearity\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3))) # Add Convolution layers\n",
    "model.add(Activation('relu')) # Add Relu activation for non-linearity\n",
    "model.add(MaxPooling2D(pool_size=(4, 4))) # Add Max pooling to lower the sptail dimension\n",
    "\n",
    "model.add(Flatten()) # Flatten the featuremaps\n",
    "model.add(Dense(units=512)) # Add dense layer with 512 neurons\n",
    "model.add(Activation('relu')) # Add Relu activation for non-linearity\n",
    "model.add(Dense(units=num_classes)) # Add final output layer for 10 classes\n",
    "model.add(Activation('softmax')) # Add softmax activation to transfer logits into probabilities\n",
    "\n",
    "# initiate SGD optimizer\n",
    "opt = keras.optimizers.SGD()\n",
    "\n",
    "# Compile the model with loss function and optimizer, and evaluate with accuracy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Setup some hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Fit the data into model\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(y_pred.shape) # 10000 samples, each sample with probaility of 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4284909e-03, 2.9643339e-01, 1.2415329e-03, 3.2413865e-03,\n",
       "       1.1167271e-03, 1.0127937e-03, 6.8496183e-06, 3.5009726e-03,\n",
       "       3.1431669e-03, 6.8787467e-01], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred[0]) # argmax to find the predict class with highest probability. 9=truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT MODIFY CODE BELOW!\n",
    "**Please screen shot your results and post it on your report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = your_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of my model on test set:  0.522\n"
     ]
    }
   ],
   "source": [
    "y_test = np.load(\"./source/y_test.npy\")\n",
    "print(\"Accuracy of my model on test set: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
